{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e747e7-1302-4c98-a1ee-13a8f589f09a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# Evaluation component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2433117-de05-4e3e-a412-bbe0089a3a34",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Setting environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ad1bb-9a6e-4e92-8ec6-26992eeee6d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Install Jupyter Kernel and python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4216e3d2-60f1-4421-8170-b53a20036779",
   "metadata": {
    "deletable": false,
    "editable": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "jq is already the newest version (1.6-2.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/310-iris\n",
      "\n",
      "  added / updated specs:\n",
      "    - dask\n",
      "    - google-cloud-aiplatform\n",
      "    - google-cloud-bigquery\n",
      "    - ipykernel\n",
      "    - ipython\n",
      "    - jupyter\n",
      "    - notebook\n",
      "    - numpy\n",
      "    - openpyxl\n",
      "    - pandas\n",
      "    - pandas-gbq\n",
      "    - pyarrow\n",
      "    - python=3.10\n",
      "    - tabulate\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.8.6-py310h2372a71_1 \n",
      "  aiosignal          conda-forge/noarch::aiosignal-1.3.1-pyhd8ed1ab_0 \n",
      "  anyio              conda-forge/noarch::anyio-4.0.0-pyhd8ed1ab_0 \n",
      "  argon2-cffi        conda-forge/noarch::argon2-cffi-23.1.0-pyhd8ed1ab_0 \n",
      "  argon2-cffi-bindi~ conda-forge/linux-64::argon2-cffi-bindings-21.2.0-py310h2372a71_4 \n",
      "  arrow              conda-forge/noarch::arrow-1.3.0-pyhd8ed1ab_0 \n",
      "  asttokens          conda-forge/noarch::asttokens-2.4.1-pyhd8ed1ab_0 \n",
      "  async-lru          conda-forge/noarch::async-lru-2.0.4-pyhd8ed1ab_0 \n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.3-pyhd8ed1ab_0 \n",
      "  attrs              conda-forge/noarch::attrs-23.1.0-pyh71513ae_1 \n",
      "  aws-c-auth         conda-forge/linux-64::aws-c-auth-0.7.6-h37ad1db_0 \n",
      "  aws-c-cal          conda-forge/linux-64::aws-c-cal-0.6.9-h3b91eb8_1 \n",
      "  aws-c-common       conda-forge/linux-64::aws-c-common-0.9.8-hd590300_0 \n",
      "  aws-c-compression  conda-forge/linux-64::aws-c-compression-0.2.17-hfd9eb17_6 \n",
      "  aws-c-event-stream conda-forge/linux-64::aws-c-event-stream-0.3.2-hae413d4_6 \n",
      "  aws-c-http         conda-forge/linux-64::aws-c-http-0.7.14-h162056d_1 \n",
      "  aws-c-io           conda-forge/linux-64::aws-c-io-0.13.35-hc23c90e_8 \n",
      "  aws-c-mqtt         conda-forge/linux-64::aws-c-mqtt-0.9.9-h1387108_0 \n",
      "  aws-c-s3           conda-forge/linux-64::aws-c-s3-0.3.24-h7630044_0 \n",
      "  aws-c-sdkutils     conda-forge/linux-64::aws-c-sdkutils-0.1.12-hfd9eb17_5 \n",
      "  aws-checksums      conda-forge/linux-64::aws-checksums-0.1.17-hfd9eb17_5 \n",
      "  aws-crt-cpp        conda-forge/linux-64::aws-crt-cpp-0.24.7-h4712614_1 \n",
      "  aws-sdk-cpp        conda-forge/linux-64::aws-sdk-cpp-1.11.182-h8beafcf_7 \n",
      "  babel              conda-forge/noarch::babel-2.13.1-pyhd8ed1ab_0 \n",
      "  backports          conda-forge/noarch::backports-1.0-pyhd8ed1ab_3 \n",
      "  backports.functoo~ conda-forge/noarch::backports.functools_lru_cache-1.6.5-pyhd8ed1ab_0 \n",
      "  beautifulsoup4     conda-forge/noarch::beautifulsoup4-4.12.2-pyha770c72_0 \n",
      "  bleach             conda-forge/noarch::bleach-6.1.0-pyhd8ed1ab_0 \n",
      "  blinker            conda-forge/noarch::blinker-1.7.0-pyhd8ed1ab_0 \n",
      "  blosc              conda-forge/linux-64::blosc-1.21.5-h0f2a231_0 \n",
      "  bokeh              conda-forge/noarch::bokeh-3.3.1-pyhd8ed1ab_0 \n",
      "  branca             conda-forge/noarch::branca-0.7.0-pyhd8ed1ab_1 \n",
      "  brotli             conda-forge/linux-64::brotli-1.1.0-hd590300_1 \n",
      "  brotli-bin         conda-forge/linux-64::brotli-bin-1.1.0-hd590300_1 \n",
      "  brotli-python      conda-forge/linux-64::brotli-python-1.1.0-py310hc6cd4ac_1 \n",
      "  bzip2              conda-forge/linux-64::bzip2-1.0.8-hd590300_5 \n",
      "  c-ares             conda-forge/linux-64::c-ares-1.21.0-hd590300_0 \n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates-2023.7.22-hbcca054_0 \n",
      "  cached-property    conda-forge/noarch::cached-property-1.5.2-hd8ed1ab_1 \n",
      "  cached_property    conda-forge/noarch::cached_property-1.5.2-pyha770c72_1 \n",
      "  cachetools         conda-forge/noarch::cachetools-5.3.2-pyhd8ed1ab_0 \n",
      "  cairo              conda-forge/linux-64::cairo-1.18.0-h3faef2a_0 \n",
      "  certifi            conda-forge/noarch::certifi-2023.7.22-pyhd8ed1ab_0 \n",
      "  cffi               conda-forge/linux-64::cffi-1.16.0-py310h2fee648_0 \n",
      "  cfitsio            conda-forge/linux-64::cfitsio-4.3.0-hbdc6101_0 \n",
      "  charset-normalizer conda-forge/noarch::charset-normalizer-3.3.2-pyhd8ed1ab_0 \n",
      "  click              conda-forge/noarch::click-8.1.7-unix_pyh707e725_0 \n",
      "  click-plugins      conda-forge/noarch::click-plugins-1.1.1-py_0 \n",
      "  cligj              conda-forge/noarch::cligj-0.7.2-pyhd8ed1ab_1 \n",
      "  cloudpickle        conda-forge/noarch::cloudpickle-3.0.0-pyhd8ed1ab_0 \n",
      "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 \n",
      "  comm               conda-forge/noarch::comm-0.1.4-pyhd8ed1ab_0 \n",
      "  contourpy          conda-forge/linux-64::contourpy-1.2.0-py310hd41b1e2_0 \n",
      "  cryptography       conda-forge/linux-64::cryptography-41.0.5-py310h75e40e8_0 \n",
      "  cycler             conda-forge/noarch::cycler-0.12.1-pyhd8ed1ab_0 \n",
      "  cytoolz            conda-forge/linux-64::cytoolz-0.12.2-py310h2372a71_1 \n",
      "  dask               conda-forge/noarch::dask-2023.11.0-pyhd8ed1ab_0 \n",
      "  dask-core          conda-forge/noarch::dask-core-2023.11.0-pyhd8ed1ab_0 \n",
      "  db-dtypes          conda-forge/noarch::db-dtypes-1.1.1-pyhd8ed1ab_0 \n",
      "  debugpy            conda-forge/linux-64::debugpy-1.8.0-py310hc6cd4ac_1 \n",
      "  decorator          conda-forge/noarch::decorator-5.1.1-pyhd8ed1ab_0 \n",
      "  defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0 \n",
      "  distributed        conda-forge/noarch::distributed-2023.11.0-pyhd8ed1ab_0 \n",
      "  entrypoints        conda-forge/noarch::entrypoints-0.4-pyhd8ed1ab_0 \n",
      "  et_xmlfile         conda-forge/noarch::et_xmlfile-1.1.0-pyhd8ed1ab_0 \n",
      "  exceptiongroup     conda-forge/noarch::exceptiongroup-1.1.3-pyhd8ed1ab_0 \n",
      "  executing          conda-forge/noarch::executing-2.0.1-pyhd8ed1ab_0 \n",
      "  expat              conda-forge/linux-64::expat-2.5.0-hcb278e6_1 \n",
      "  fastavro           conda-forge/linux-64::fastavro-1.9.0-py310h2372a71_0 \n",
      "  fiona              conda-forge/linux-64::fiona-1.9.5-py310h0a1e91f_1 \n",
      "  folium             conda-forge/noarch::folium-0.15.0-pyhd8ed1ab_0 \n",
      "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
      "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
      "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
      "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-hab24e00_0 \n",
      "  fontconfig         conda-forge/linux-64::fontconfig-2.14.2-h14ed4e7_0 \n",
      "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
      "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n",
      "  fonttools          conda-forge/linux-64::fonttools-4.44.1-py310h2372a71_0 \n",
      "  fqdn               conda-forge/noarch::fqdn-1.5.1-pyhd8ed1ab_0 \n",
      "  freetype           conda-forge/linux-64::freetype-2.12.1-h267a509_2 \n",
      "  freexl             conda-forge/linux-64::freexl-2.0.0-h743c826_0 \n",
      "  frozenlist         conda-forge/linux-64::frozenlist-1.4.0-py310h2372a71_1 \n",
      "  fsspec             conda-forge/noarch::fsspec-2023.10.0-pyhca7485f_0 \n",
      "  gdal               conda-forge/linux-64::gdal-3.8.0-py310h5c4b078_3 \n",
      "  geopandas          conda-forge/noarch::geopandas-0.14.1-pyhd8ed1ab_0 \n",
      "  geopandas-base     conda-forge/noarch::geopandas-base-0.14.1-pyha770c72_0 \n",
      "  geos               conda-forge/linux-64::geos-3.12.0-h59595ed_0 \n",
      "  geotiff            conda-forge/linux-64::geotiff-1.7.1-hf074850_14 \n",
      "  gettext            conda-forge/linux-64::gettext-0.21.1-h27087fc_0 \n",
      "  gflags             conda-forge/linux-64::gflags-2.2.2-he1b5a44_1004 \n",
      "  giflib             conda-forge/linux-64::giflib-5.2.1-h0b41bf4_3 \n",
      "  glog               conda-forge/linux-64::glog-0.6.0-h6f12383_0 \n",
      "  gmp                conda-forge/linux-64::gmp-6.3.0-h59595ed_0 \n",
      "  google-api-core    conda-forge/noarch::google-api-core-2.14.0-pyhd8ed1ab_0 \n",
      "  google-api-core-g~ conda-forge/noarch::google-api-core-grpc-2.14.0-hd8ed1ab_0 \n",
      "  google-auth        conda-forge/noarch::google-auth-2.23.4-pyhca7485f_0 \n",
      "  google-auth-oauth~ conda-forge/noarch::google-auth-oauthlib-1.1.0-pyhd8ed1ab_0 \n",
      "  google-cloud-aipl~ conda-forge/linux-64::google-cloud-aiplatform-1.36.3-py310hff52083_0 \n",
      "  google-cloud-bigq~ conda-forge/noarch::google-cloud-bigquery-3.13.0-pyhd8ed1ab_0 \n",
      "  google-cloud-bigq~ conda-forge/noarch::google-cloud-bigquery-core-3.13.0-pyhd8ed1ab_0 \n",
      "  google-cloud-bigq~ conda-forge/noarch::google-cloud-bigquery-storage-2.22.0-pyh1a96a4e_0 \n",
      "  google-cloud-bigq~ conda-forge/noarch::google-cloud-bigquery-storage-core-2.22.0-pyh1a96a4e_0 \n",
      "  google-cloud-core  conda-forge/noarch::google-cloud-core-2.3.3-pyhd8ed1ab_0 \n",
      "  google-cloud-reso~ conda-forge/noarch::google-cloud-resource-manager-1.10.4-pyhd8ed1ab_0 \n",
      "  google-cloud-stor~ conda-forge/noarch::google-cloud-storage-2.13.0-pyhca7485f_0 \n",
      "  google-crc32c      conda-forge/linux-64::google-crc32c-1.1.2-py310hc5c09a0_5 \n",
      "  google-resumable-~ conda-forge/noarch::google-resumable-media-2.6.0-pyhd8ed1ab_0 \n",
      "  googleapis-common~ conda-forge/noarch::googleapis-common-protos-1.61.0-pyhd8ed1ab_0 \n",
      "  googleapis-common~ conda-forge/noarch::googleapis-common-protos-grpc-1.61.0-pyhd8ed1ab_0 \n",
      "  grpc-google-iam-v1 conda-forge/noarch::grpc-google-iam-v1-0.12.6-pyhd8ed1ab_1 \n",
      "  grpcio             conda-forge/linux-64::grpcio-1.59.2-py310h1b8f574_0 \n",
      "  grpcio-status      conda-forge/noarch::grpcio-status-1.59.2-pyhd8ed1ab_0 \n",
      "  hdf4               conda-forge/linux-64::hdf4-4.2.15-h2a13503_7 \n",
      "  hdf5               conda-forge/linux-64::hdf5-1.14.2-nompi_h4f84152_100 \n",
      "  icu                conda-forge/linux-64::icu-73.2-h59595ed_0 \n",
      "  idna               conda-forge/noarch::idna-3.4-pyhd8ed1ab_0 \n",
      "  importlib-metadata conda-forge/noarch::importlib-metadata-6.8.0-pyha770c72_0 \n",
      "  importlib_metadata conda-forge/noarch::importlib_metadata-6.8.0-hd8ed1ab_0 \n",
      "  importlib_resourc~ conda-forge/noarch::importlib_resources-6.1.1-pyhd8ed1ab_0 \n",
      "  ipykernel          conda-forge/noarch::ipykernel-6.26.0-pyhf8b6a83_0 \n",
      "  ipython            conda-forge/noarch::ipython-8.17.2-pyh41d4057_0 \n",
      "  ipywidgets         conda-forge/noarch::ipywidgets-8.1.1-pyhd8ed1ab_0 \n",
      "  isoduration        conda-forge/noarch::isoduration-20.11.0-pyhd8ed1ab_0 \n",
      "  jedi               conda-forge/noarch::jedi-0.19.1-pyhd8ed1ab_0 \n",
      "  jinja2             conda-forge/noarch::jinja2-3.1.2-pyhd8ed1ab_1 \n",
      "  joblib             conda-forge/noarch::joblib-1.3.2-pyhd8ed1ab_0 \n",
      "  json-c             conda-forge/linux-64::json-c-0.17-h7ab15ed_0 \n",
      "  json5              conda-forge/noarch::json5-0.9.14-pyhd8ed1ab_0 \n",
      "  jsonpointer        conda-forge/linux-64::jsonpointer-2.4-py310hff52083_3 \n",
      "  jsonschema         conda-forge/noarch::jsonschema-4.19.2-pyhd8ed1ab_0 \n",
      "  jsonschema-specif~ conda-forge/noarch::jsonschema-specifications-2023.11.1-pyhd8ed1ab_0 \n",
      "  jsonschema-with-f~ conda-forge/noarch::jsonschema-with-format-nongpl-4.19.2-pyhd8ed1ab_0 \n",
      "  jupyter            conda-forge/noarch::jupyter-1.0.0-pyhd8ed1ab_10 \n",
      "  jupyter-lsp        conda-forge/noarch::jupyter-lsp-2.2.0-pyhd8ed1ab_0 \n",
      "  jupyter_client     conda-forge/noarch::jupyter_client-8.6.0-pyhd8ed1ab_0 \n",
      "  jupyter_console    conda-forge/noarch::jupyter_console-6.6.3-pyhd8ed1ab_0 \n",
      "  jupyter_core       conda-forge/linux-64::jupyter_core-5.5.0-py310hff52083_0 \n",
      "  jupyter_events     conda-forge/noarch::jupyter_events-0.9.0-pyhd8ed1ab_0 \n",
      "  jupyter_server     conda-forge/noarch::jupyter_server-2.10.1-pyhd8ed1ab_0 \n",
      "  jupyter_server_te~ conda-forge/noarch::jupyter_server_terminals-0.4.4-pyhd8ed1ab_1 \n",
      "  jupyterlab         conda-forge/noarch::jupyterlab-4.0.8-pyhd8ed1ab_0 \n",
      "  jupyterlab_pygmen~ conda-forge/noarch::jupyterlab_pygments-0.2.2-pyhd8ed1ab_0 \n",
      "  jupyterlab_server  conda-forge/noarch::jupyterlab_server-2.25.1-pyhd8ed1ab_0 \n",
      "  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-3.0.9-pyhd8ed1ab_0 \n",
      "  kealib             conda-forge/linux-64::kealib-1.5.2-hcd42e92_1 \n",
      "  keyutils           conda-forge/linux-64::keyutils-1.6.1-h166bdaf_0 \n",
      "  kiwisolver         conda-forge/linux-64::kiwisolver-1.4.5-py310hd41b1e2_1 \n",
      "  krb5               conda-forge/linux-64::krb5-1.21.2-h659d440_0 \n",
      "  lcms2              conda-forge/linux-64::lcms2-2.15-hb7c19ff_3 \n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.40-h41732ed_0 \n",
      "  lerc               conda-forge/linux-64::lerc-4.0.0-h27087fc_0 \n",
      "  libabseil          conda-forge/linux-64::libabseil-20230802.1-cxx17_h59595ed_0 \n",
      "  libaec             conda-forge/linux-64::libaec-1.1.2-h59595ed_1 \n",
      "  libarchive         conda-forge/linux-64::libarchive-3.7.2-h039dbb9_0 \n",
      "  libarrow           conda-forge/linux-64::libarrow-14.0.1-h4df1b6a_3_cpu \n",
      "  libarrow-acero     conda-forge/linux-64::libarrow-acero-14.0.1-h59595ed_3_cpu \n",
      "  libarrow-dataset   conda-forge/linux-64::libarrow-dataset-14.0.1-h59595ed_3_cpu \n",
      "  libarrow-flight    conda-forge/linux-64::libarrow-flight-14.0.1-h120cb0d_3_cpu \n",
      "  libarrow-flight-s~ conda-forge/linux-64::libarrow-flight-sql-14.0.1-h61ff412_3_cpu \n",
      "  libarrow-gandiva   conda-forge/linux-64::libarrow-gandiva-14.0.1-hacb8726_3_cpu \n",
      "  libarrow-substrait conda-forge/linux-64::libarrow-substrait-14.0.1-h61ff412_3_cpu \n",
      "  libblas            conda-forge/linux-64::libblas-3.9.0-19_linux64_openblas \n",
      "  libboost-headers   conda-forge/linux-64::libboost-headers-1.82.0-ha770c72_6 \n",
      "  libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.1.0-hd590300_1 \n",
      "  libbrotlidec       conda-forge/linux-64::libbrotlidec-1.1.0-hd590300_1 \n",
      "  libbrotlienc       conda-forge/linux-64::libbrotlienc-1.1.0-hd590300_1 \n",
      "  libcblas           conda-forge/linux-64::libcblas-3.9.0-19_linux64_openblas \n",
      "  libcrc32c          conda-forge/linux-64::libcrc32c-1.1.2-h9c3ff4c_0 \n",
      "  libcurl            conda-forge/linux-64::libcurl-8.4.0-hca28451_0 \n",
      "  libdeflate         conda-forge/linux-64::libdeflate-1.19-hd590300_0 \n",
      "  libedit            conda-forge/linux-64::libedit-3.1.20191231-he28a2e2_2 \n",
      "  libev              conda-forge/linux-64::libev-4.33-h516909a_1 \n",
      "  libevent           conda-forge/linux-64::libevent-2.1.12-hf998b51_1 \n",
      "  libexpat           conda-forge/linux-64::libexpat-2.5.0-hcb278e6_1 \n",
      "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-13.2.0-h807b86a_3 \n",
      "  libgdal            conda-forge/linux-64::libgdal-3.8.0-h12dd931_3 \n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-13.2.0-h69a702a_3 \n",
      "  libgfortran5       conda-forge/linux-64::libgfortran5-13.2.0-ha4646dd_3 \n",
      "  libglib            conda-forge/linux-64::libglib-2.78.1-h783c2da_1 \n",
      "  libgomp            conda-forge/linux-64::libgomp-13.2.0-h807b86a_3 \n",
      "  libgoogle-cloud    conda-forge/linux-64::libgoogle-cloud-2.12.0-h5206363_4 \n",
      "  libgrpc            conda-forge/linux-64::libgrpc-1.59.2-hd6c4280_0 \n",
      "  libiconv           conda-forge/linux-64::libiconv-1.17-h166bdaf_0 \n",
      "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.0.0-hd590300_1 \n",
      "  libkml             conda-forge/linux-64::libkml-1.3.0-h01aab08_1018 \n",
      "  liblapack          conda-forge/linux-64::liblapack-3.9.0-19_linux64_openblas \n",
      "  libllvm15          conda-forge/linux-64::libllvm15-15.0.7-h5cf9203_3 \n",
      "  libnetcdf          conda-forge/linux-64::libnetcdf-4.9.2-nompi_h80fb2b6_112 \n",
      "  libnghttp2         conda-forge/linux-64::libnghttp2-1.58.0-h47da74e_0 \n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
      "  libnuma            conda-forge/linux-64::libnuma-2.0.16-h0b41bf4_1 \n",
      "  libopenblas        conda-forge/linux-64::libopenblas-0.3.24-pthreads_h413a1c8_0 \n",
      "  libparquet         conda-forge/linux-64::libparquet-14.0.1-h352af49_3_cpu \n",
      "  libpng             conda-forge/linux-64::libpng-1.6.39-h753d276_0 \n",
      "  libpq              conda-forge/linux-64::libpq-16.1-hfc447b1_0 \n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-4.24.4-hf27288f_0 \n",
      "  libre2-11          conda-forge/linux-64::libre2-11-2023.06.02-h7a70373_0 \n",
      "  librttopo          conda-forge/linux-64::librttopo-1.1.0-hb58d41b_14 \n",
      "  libsodium          conda-forge/linux-64::libsodium-1.0.18-h36c2ea0_1 \n",
      "  libspatialindex    conda-forge/linux-64::libspatialindex-1.9.3-h9c3ff4c_4 \n",
      "  libspatialite      conda-forge/linux-64::libspatialite-5.1.0-h090f1da_1 \n",
      "  libsqlite          conda-forge/linux-64::libsqlite-3.44.0-h2797004_0 \n",
      "  libssh2            conda-forge/linux-64::libssh2-1.11.0-h0841786_0 \n",
      "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-13.2.0-h7e041cc_3 \n",
      "  libthrift          conda-forge/linux-64::libthrift-0.19.0-hb90f79a_1 \n",
      "  libtiff            conda-forge/linux-64::libtiff-4.6.0-ha9c0a0a_2 \n",
      "  libutf8proc        conda-forge/linux-64::libutf8proc-2.8.0-h166bdaf_0 \n",
      "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
      "  libwebp-base       conda-forge/linux-64::libwebp-base-1.3.2-hd590300_0 \n",
      "  libxcb             conda-forge/linux-64::libxcb-1.15-h0b41bf4_0 \n",
      "  libxml2            conda-forge/linux-64::libxml2-2.11.5-h232c23b_1 \n",
      "  libzip             conda-forge/linux-64::libzip-1.10.1-h2629f0a_3 \n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.13-hd590300_5 \n",
      "  locket             conda-forge/noarch::locket-1.0.0-pyhd8ed1ab_0 \n",
      "  lz4                conda-forge/linux-64::lz4-4.3.2-py310h350c4a5_1 \n",
      "  lz4-c              conda-forge/linux-64::lz4-c-1.9.4-hcb278e6_0 \n",
      "  lzo                conda-forge/linux-64::lzo-2.10-h516909a_1000 \n",
      "  mapclassify        conda-forge/noarch::mapclassify-2.6.1-pyhd8ed1ab_0 \n",
      "  markupsafe         conda-forge/linux-64::markupsafe-2.1.3-py310h2372a71_1 \n",
      "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.8.1-py310h62c0568_0 \n",
      "  matplotlib-inline  conda-forge/noarch::matplotlib-inline-0.1.6-pyhd8ed1ab_0 \n",
      "  minizip            conda-forge/linux-64::minizip-4.0.3-h0ab5242_0 \n",
      "  mistune            conda-forge/noarch::mistune-3.0.2-pyhd8ed1ab_0 \n",
      "  msgpack-python     conda-forge/linux-64::msgpack-python-1.0.6-py310hd41b1e2_0 \n",
      "  multidict          conda-forge/linux-64::multidict-6.0.4-py310h2372a71_1 \n",
      "  munch              conda-forge/noarch::munch-4.0.0-pyhd8ed1ab_0 \n",
      "  munkres            conda-forge/noarch::munkres-1.1.4-pyh9f0ad1d_0 \n",
      "  nbclient           conda-forge/noarch::nbclient-0.8.0-pyhd8ed1ab_0 \n",
      "  nbconvert          conda-forge/noarch::nbconvert-7.11.0-pyhd8ed1ab_0 \n",
      "  nbconvert-core     conda-forge/noarch::nbconvert-core-7.11.0-pyhd8ed1ab_0 \n",
      "  nbconvert-pandoc   conda-forge/noarch::nbconvert-pandoc-7.11.0-pyhd8ed1ab_0 \n",
      "  nbformat           conda-forge/noarch::nbformat-5.9.2-pyhd8ed1ab_0 \n",
      "  ncurses            conda-forge/linux-64::ncurses-6.4-h59595ed_2 \n",
      "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.5.8-pyhd8ed1ab_0 \n",
      "  networkx           conda-forge/noarch::networkx-3.2.1-pyhd8ed1ab_0 \n",
      "  notebook           conda-forge/noarch::notebook-7.0.6-pyhd8ed1ab_0 \n",
      "  notebook-shim      conda-forge/noarch::notebook-shim-0.2.3-pyhd8ed1ab_0 \n",
      "  nspr               conda-forge/linux-64::nspr-4.35-h27087fc_0 \n",
      "  nss                conda-forge/linux-64::nss-3.94-h1d7d5a4_0 \n",
      "  numpy              conda-forge/linux-64::numpy-1.26.0-py310hb13e2d6_0 \n",
      "  oauthlib           conda-forge/noarch::oauthlib-3.2.2-pyhd8ed1ab_0 \n",
      "  openjpeg           conda-forge/linux-64::openjpeg-2.5.0-h488ebb8_3 \n",
      "  openpyxl           conda-forge/linux-64::openpyxl-3.1.2-py310h2372a71_1 \n",
      "  openssl            conda-forge/linux-64::openssl-3.1.4-hd590300_0 \n",
      "  orc                conda-forge/linux-64::orc-1.9.0-h4b38347_4 \n",
      "  overrides          conda-forge/noarch::overrides-7.4.0-pyhd8ed1ab_0 \n",
      "  packaging          conda-forge/noarch::packaging-23.2-pyhd8ed1ab_0 \n",
      "  pandas             conda-forge/linux-64::pandas-2.1.3-py310hcc13569_0 \n",
      "  pandas-gbq         conda-forge/noarch::pandas-gbq-0.19.2-pyh1a96a4e_0 \n",
      "  pandoc             conda-forge/linux-64::pandoc-3.1.3-h32600fe_0 \n",
      "  pandocfilters      conda-forge/noarch::pandocfilters-1.5.0-pyhd8ed1ab_0 \n",
      "  parso              conda-forge/noarch::parso-0.8.3-pyhd8ed1ab_0 \n",
      "  partd              conda-forge/noarch::partd-1.4.1-pyhd8ed1ab_0 \n",
      "  pcre2              conda-forge/linux-64::pcre2-10.42-hcad00b1_0 \n",
      "  pexpect            conda-forge/noarch::pexpect-4.8.0-pyh1a96a4e_2 \n",
      "  pickleshare        conda-forge/noarch::pickleshare-0.7.5-py_1003 \n",
      "  pillow             conda-forge/linux-64::pillow-10.1.0-py310h01dd4db_0 \n",
      "  pip                conda-forge/noarch::pip-23.3.1-pyhd8ed1ab_0 \n",
      "  pixman             conda-forge/linux-64::pixman-0.42.2-h59595ed_0 \n",
      "  pkgutil-resolve-n~ conda-forge/noarch::pkgutil-resolve-name-1.3.10-pyhd8ed1ab_1 \n",
      "  platformdirs       conda-forge/noarch::platformdirs-4.0.0-pyhd8ed1ab_0 \n",
      "  poppler            conda-forge/linux-64::poppler-23.11.0-h590f24d_0 \n",
      "  poppler-data       conda-forge/noarch::poppler-data-0.4.12-hd8ed1ab_0 \n",
      "  postgresql         conda-forge/linux-64::postgresql-16.1-h8972f4a_0 \n",
      "  proj               conda-forge/linux-64::proj-9.3.0-h1d62c97_2 \n",
      "  prometheus_client  conda-forge/noarch::prometheus_client-0.18.0-pyhd8ed1ab_1 \n",
      "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.41-pyha770c72_0 \n",
      "  prompt_toolkit     conda-forge/noarch::prompt_toolkit-3.0.41-hd8ed1ab_0 \n",
      "  proto-plus         conda-forge/noarch::proto-plus-1.22.3-pyhd8ed1ab_0 \n",
      "  protobuf           conda-forge/linux-64::protobuf-4.24.4-py310h620c231_0 \n",
      "  psutil             conda-forge/linux-64::psutil-5.9.5-py310h2372a71_1 \n",
      "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001 \n",
      "  ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd3deb0d_0 \n",
      "  pure_eval          conda-forge/noarch::pure_eval-0.2.2-pyhd8ed1ab_0 \n",
      "  pyarrow            conda-forge/linux-64::pyarrow-14.0.1-py310hf9e7431_3_cpu \n",
      "  pyarrow-hotfix     conda-forge/noarch::pyarrow-hotfix-0.5-pyhd8ed1ab_0 \n",
      "  pyasn1             conda-forge/noarch::pyasn1-0.5.0-pyhd8ed1ab_0 \n",
      "  pyasn1-modules     conda-forge/noarch::pyasn1-modules-0.3.0-pyhd8ed1ab_0 \n",
      "  pycparser          conda-forge/noarch::pycparser-2.21-pyhd8ed1ab_0 \n",
      "  pydata-google-auth conda-forge/noarch::pydata-google-auth-1.8.2-pyhd8ed1ab_0 \n",
      "  pygments           conda-forge/noarch::pygments-2.16.1-pyhd8ed1ab_0 \n",
      "  pyjwt              conda-forge/noarch::pyjwt-2.8.0-pyhd8ed1ab_0 \n",
      "  pyopenssl          conda-forge/noarch::pyopenssl-23.3.0-pyhd8ed1ab_0 \n",
      "  pyparsing          conda-forge/noarch::pyparsing-3.1.1-pyhd8ed1ab_0 \n",
      "  pyproj             conda-forge/linux-64::pyproj-3.6.1-py310h32c33b7_4 \n",
      "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyha2e5f31_6 \n",
      "  python             conda-forge/linux-64::python-3.10.13-hd12c33a_0_cpython \n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0 \n",
      "  python-fastjsonsc~ conda-forge/noarch::python-fastjsonschema-2.19.0-pyhd8ed1ab_0 \n",
      "  python-json-logger conda-forge/noarch::python-json-logger-2.0.7-pyhd8ed1ab_0 \n",
      "  python-tzdata      conda-forge/noarch::python-tzdata-2023.3-pyhd8ed1ab_0 \n",
      "  python_abi         conda-forge/linux-64::python_abi-3.10-4_cp310 \n",
      "  pytz               conda-forge/noarch::pytz-2023.3.post1-pyhd8ed1ab_0 \n",
      "  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0 \n",
      "  pyyaml             conda-forge/linux-64::pyyaml-6.0.1-py310h2372a71_1 \n",
      "  pyzmq              conda-forge/linux-64::pyzmq-25.1.1-py310h795f18f_2 \n",
      "  qtconsole-base     conda-forge/noarch::qtconsole-base-5.5.0-pyha770c72_0 \n",
      "  qtpy               conda-forge/noarch::qtpy-2.4.1-pyhd8ed1ab_0 \n",
      "  rdma-core          conda-forge/linux-64::rdma-core-28.9-h59595ed_1 \n",
      "  re2                conda-forge/linux-64::re2-2023.06.02-h2873b5e_0 \n",
      "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
      "  referencing        conda-forge/noarch::referencing-0.31.0-pyhd8ed1ab_0 \n",
      "  requests           conda-forge/noarch::requests-2.31.0-pyhd8ed1ab_0 \n",
      "  requests-oauthlib  conda-forge/noarch::requests-oauthlib-1.3.1-pyhd8ed1ab_0 \n",
      "  rfc3339-validator  conda-forge/noarch::rfc3339-validator-0.1.4-pyhd8ed1ab_0 \n",
      "  rfc3986-validator  conda-forge/noarch::rfc3986-validator-0.1.1-pyh9f0ad1d_0 \n",
      "  rpds-py            conda-forge/linux-64::rpds-py-0.12.0-py310hcb5633a_0 \n",
      "  rsa                conda-forge/noarch::rsa-4.9-pyhd8ed1ab_0 \n",
      "  rtree              conda-forge/linux-64::rtree-1.1.0-py310hbdcdc62_0 \n",
      "  s2n                conda-forge/linux-64::s2n-1.3.56-h06160fa_0 \n",
      "  scikit-learn       conda-forge/linux-64::scikit-learn-1.3.2-py310h1fdf081_1 \n",
      "  scipy              conda-forge/linux-64::scipy-1.11.3-py310hb13e2d6_1 \n",
      "  send2trash         conda-forge/noarch::send2trash-1.8.2-pyh41d4057_0 \n",
      "  setuptools         conda-forge/noarch::setuptools-68.2.2-pyhd8ed1ab_0 \n",
      "  shapely            conda-forge/linux-64::shapely-2.0.2-py310h7dcad9a_0 \n",
      "  six                conda-forge/noarch::six-1.16.0-pyh6c4a22f_0 \n",
      "  snappy             conda-forge/linux-64::snappy-1.1.10-h9fff704_0 \n",
      "  sniffio            conda-forge/noarch::sniffio-1.3.0-pyhd8ed1ab_0 \n",
      "  sortedcontainers   conda-forge/noarch::sortedcontainers-2.4.0-pyhd8ed1ab_0 \n",
      "  soupsieve          conda-forge/noarch::soupsieve-2.5-pyhd8ed1ab_1 \n",
      "  sqlite             conda-forge/linux-64::sqlite-3.44.0-h2c6b66d_0 \n",
      "  stack_data         conda-forge/noarch::stack_data-0.6.2-pyhd8ed1ab_0 \n",
      "  tabulate           conda-forge/noarch::tabulate-0.9.0-pyhd8ed1ab_1 \n",
      "  tblib              conda-forge/noarch::tblib-2.0.0-pyhd8ed1ab_0 \n",
      "  terminado          conda-forge/noarch::terminado-0.18.0-pyh0d859eb_0 \n",
      "  threadpoolctl      conda-forge/noarch::threadpoolctl-3.2.0-pyha21a80b_0 \n",
      "  tiledb             conda-forge/linux-64::tiledb-2.16.3-h8c794c1_3 \n",
      "  tinycss2           conda-forge/noarch::tinycss2-1.2.1-pyhd8ed1ab_0 \n",
      "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
      "  tomli              conda-forge/noarch::tomli-2.0.1-pyhd8ed1ab_0 \n",
      "  toolz              conda-forge/noarch::toolz-0.12.0-pyhd8ed1ab_0 \n",
      "  tornado            conda-forge/linux-64::tornado-6.3.3-py310h2372a71_1 \n",
      "  tqdm               conda-forge/noarch::tqdm-4.66.1-pyhd8ed1ab_0 \n",
      "  traitlets          conda-forge/noarch::traitlets-5.13.0-pyhd8ed1ab_0 \n",
      "  types-python-date~ conda-forge/noarch::types-python-dateutil-2.8.19.14-pyhd8ed1ab_0 \n",
      "  typing-extensions  conda-forge/noarch::typing-extensions-4.8.0-hd8ed1ab_0 \n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-4.8.0-pyha770c72_0 \n",
      "  typing_utils       conda-forge/noarch::typing_utils-0.1.0-pyhd8ed1ab_0 \n",
      "  tzcode             conda-forge/linux-64::tzcode-2023c-h0b41bf4_0 \n",
      "  tzdata             conda-forge/noarch::tzdata-2023c-h71feb2d_0 \n",
      "  ucx                conda-forge/linux-64::ucx-1.15.0-h64cca9d_0 \n",
      "  unicodedata2       conda-forge/linux-64::unicodedata2-15.1.0-py310h2372a71_0 \n",
      "  uri-template       conda-forge/noarch::uri-template-1.3.0-pyhd8ed1ab_0 \n",
      "  uriparser          conda-forge/linux-64::uriparser-0.9.7-hcb278e6_1 \n",
      "  urllib3            conda-forge/noarch::urllib3-2.1.0-pyhd8ed1ab_0 \n",
      "  wcwidth            conda-forge/noarch::wcwidth-0.2.10-pyhd8ed1ab_0 \n",
      "  webcolors          conda-forge/noarch::webcolors-1.13-pyhd8ed1ab_0 \n",
      "  webencodings       conda-forge/noarch::webencodings-0.5.1-pyhd8ed1ab_2 \n",
      "  websocket-client   conda-forge/noarch::websocket-client-1.6.4-pyhd8ed1ab_0 \n",
      "  wheel              conda-forge/noarch::wheel-0.41.3-pyhd8ed1ab_0 \n",
      "  widgetsnbextension conda-forge/noarch::widgetsnbextension-4.0.9-pyhd8ed1ab_0 \n",
      "  xerces-c           conda-forge/linux-64::xerces-c-3.2.4-hac6953d_3 \n",
      "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002 \n",
      "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.1-hd590300_0 \n",
      "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.4-h7391055_0 \n",
      "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.7-h8ee46fc_0 \n",
      "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.11-hd590300_0 \n",
      "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0 \n",
      "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h0b41bf4_2 \n",
      "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.11-hd590300_0 \n",
      "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002 \n",
      "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h0b41bf4_1003 \n",
      "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007 \n",
      "  xyzservices        conda-forge/noarch::xyzservices-2023.10.1-pyhd8ed1ab_0 \n",
      "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n",
      "  yaml               conda-forge/linux-64::yaml-0.2.5-h7f98852_2 \n",
      "  yarl               conda-forge/linux-64::yarl-1.9.2-py310h2372a71_1 \n",
      "  zeromq             conda-forge/linux-64::zeromq-4.3.5-h59595ed_0 \n",
      "  zict               conda-forge/noarch::zict-3.0.0-pyhd8ed1ab_0 \n",
      "  zipp               conda-forge/noarch::zipp-3.17.0-pyhd8ed1ab_0 \n",
      "  zlib               conda-forge/linux-64::zlib-1.2.13-hd590300_5 \n",
      "  zstd               conda-forge/linux-64::zstd-1.5.5-hfc55251_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate 310-iris\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'doctor', 'repoquery', 'env')\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: /opt/conda/envs/310-test\n",
      "\n",
      "config/install_env_kernel.sh: line 30: ipython: command not found\n",
      "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'deactivate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'doctor', 'repoquery', 'env')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated display_name in /opt/conda/envs/310-iris/share/jupyter/kernels/python3/kernel.json to Python (310-iris)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'doctor', 'repoquery', 'env')\n",
      "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'deactivate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'doctor', 'repoquery', 'env')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual environment '310-iris' created and added to Jupyter kernels.\n",
      "To use it, start Jupyter Notebook and select 'Python (310-iris)' kernel.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x config/install_env_kernel.sh\n",
    "bash config/install_env_kernel.sh -n 310-iris -p 3.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e6be5-314e-4447-945c-048b55415930",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "*** **Now you have to restart this notebook and search the new kernel to activate it!** ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602efbf5-2ff4-4e9d-b417-4ce3fa29d07d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Install environment dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e007752-48a7-4dbc-a7e0-810378d72167",
   "metadata": {
    "deletable": false,
    "editable": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bigframes in /opt/conda/envs/310-iris/lib/python3.10/site-packages (0.14.1)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/envs/310-iris/lib/python3.10/site-packages (12.0.1)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: cloudpickle>=2.0.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.3.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (2023.10.0)\n",
      "Requirement already satisfied: gcsfs>=2023.3.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (2023.10.0)\n",
      "Requirement already satisfied: geopandas>=0.12.2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (0.14.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>2.14.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (2.23.4)\n",
      "Requirement already satisfied: google-cloud-bigquery>=3.10.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (3.13.0)\n",
      "Requirement already satisfied: google-cloud-functions>=1.10.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (1.13.3)\n",
      "Requirement already satisfied: google-cloud-bigquery-connection>=1.12.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (1.13.2)\n",
      "Requirement already satisfied: google-cloud-iam>=2.12.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (2.12.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager>=1.10.3 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (1.10.4)\n",
      "Requirement already satisfied: google-cloud-storage>=2.0.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (2.13.0)\n",
      "Requirement already satisfied: ibis-framework<7.0.0dev,>=6.2.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (6.2.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (2.1.3)\n",
      "Requirement already satisfied: pydata-google-auth>=1.8.2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (1.8.2)\n",
      "Requirement already satisfied: requests>=2.27.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=1.2.2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (1.3.2)\n",
      "Requirement already satisfied: sqlalchemy<3.0dev,>=1.4 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (2.0.23)\n",
      "Requirement already satisfied: ipywidgets>=7.7.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (8.1.1)\n",
      "Requirement already satisfied: humanize>=4.6.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from bigframes) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pyarrow) (1.26.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from gcsfs>=2023.3.0->bigframes) (3.8.6)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from gcsfs>=2023.3.0->bigframes) (5.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from gcsfs>=2023.3.0->bigframes) (1.1.0)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from geopandas>=0.12.2->bigframes) (1.9.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from geopandas>=0.12.2->bigframes) (23.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from geopandas>=0.12.2->bigframes) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from geopandas>=0.12.2->bigframes) (2.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-auth<3.0dev,>2.14.1->bigframes) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-auth<3.0dev,>2.14.1->bigframes) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-auth<3.0dev,>2.14.1->bigframes) (4.9)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (1.59.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (2.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (1.22.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (2.6.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (4.24.4)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery-connection>=1.12.0->bigframes) (0.12.6)\n",
      "Requirement already satisfied: db-dtypes<2.0.0dev,>=0.3.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (1.1.1)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.6.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (2.22.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-cloud-storage>=2.0.0->bigframes) (1.1.2)\n",
      "Requirement already satisfied: atpublic<5,>=2.3 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (4.0)\n",
      "Requirement already satisfied: bidict<1,>=0.22.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (0.22.1)\n",
      "Requirement already satisfied: filelock<4,>=3.7.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (3.13.1)\n",
      "Requirement already satisfied: multipledispatch<2,>=0.6 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (1.0.0)\n",
      "Requirement already satisfied: parsy<3,>=2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (2.1)\n",
      "Requirement already satisfied: pooch<2,>=1.6.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pooch[progress,xxhash]<2,>=1.6.0->ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (1.8.0)\n",
      "Requirement already satisfied: pytz>=2022.7 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (2023.3.post1)\n",
      "Requirement already satisfied: rich<14,>=12.4.4 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (13.7.0)\n",
      "Requirement already satisfied: sqlglot<18,>=10.4.3 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (17.16.2)\n",
      "Requirement already satisfied: toolz<1,>=0.11 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (4.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipywidgets>=7.7.1->bigframes) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipywidgets>=7.7.1->bigframes) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipywidgets>=7.7.1->bigframes) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipywidgets>=7.7.1->bigframes) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipywidgets>=7.7.1->bigframes) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pandas>=1.5.0->bigframes) (2023.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pydata-google-auth>=1.8.2->bigframes) (68.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from requests>=2.27.1->bigframes) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from requests>=2.27.1->bigframes) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from requests>=2.27.1->bigframes) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from requests>=2.27.1->bigframes) (2023.7.22)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from scikit-learn>=1.2.2->bigframes) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from scikit-learn>=1.2.2->bigframes) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from scikit-learn>=1.2.2->bigframes) (3.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from sqlalchemy<3.0dev,>=1.4->bigframes) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (1.3.1)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.2->bigframes) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.2->bigframes) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.2->bigframes) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.2->bigframes) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (1.61.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery>=3.10.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes) (1.59.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs>=2023.3.0->bigframes) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from google-crc32c<2.0dev,>=1.0->google-cloud-storage>=2.0.0->bigframes) (1.16.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (4.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pooch<2,>=1.6.0->pooch[progress,xxhash]<2,>=1.6.0->ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (4.0.0)\n",
      "Requirement already satisfied: xxhash>=1.4.3 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pooch[progress,xxhash]<2,>=1.6.0->ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (3.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.41.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pooch[progress,xxhash]<2,>=1.6.0->ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (4.66.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>2.14.1->bigframes) (0.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from rich<14,>=12.4.4->ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (3.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-cloud-storage>=2.0.0->bigframes) (2.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (0.8.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=12.4.4->ibis-framework<7.0.0dev,>=6.2.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (0.2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2023.3.0->bigframes) (3.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/envs/310-iris/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.7.1->bigframes) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -U bigframes pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b2d82-6dc5-4f3e-a973-93dd4c10f4ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Executable Code in Vertex Training as Custom Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc87a0-84ea-4688-a038-4e4a08d454c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Define input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6678c4a5-0732-41c2-9c6a-df2f831b48df",
   "metadata": {
    "deletable": false,
    "editable": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input-data-definition (DON'T REMOVE THIS COMMENT)\n",
    "project_id = 'ml-framework-maas'\n",
    "input_files_queries = ['input_data.sql']\n",
    "valid_test_rate = [0, 0.2]\n",
    "output_tables = [\"model_test_iris.train_x\", \"model_test_iris.test_x\", \"model_test_iris.train_y\", \"model_test_iris.test_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2966281e-bb8c-4cfb-a3e0-6584a1eff6a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Code to ingest input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43413cca-ff9c-4145-a0ec-b5ae4cba46b4",
   "metadata": {
    "deletable": false,
    "editable": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input-data-ingestion (DON'T REMOVE THIS COMMENT)\n",
    "import bigframes.pandas as bf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List\n",
    "\n",
    "# Auxiliar functions\n",
    "def modify_query_file(input_name: str, replacements: dict={}, path='../scripts/queries/'):\n",
    "    \"\"\"\n",
    "    Modifies file in place with a dictionary of string replacements\n",
    "    \"\"\"\n",
    "    with open(path+input_name, 'r') as file :\n",
    "        filedata = file.read()\n",
    "    if replacements:\n",
    "        for key, value in replacements.items():\n",
    "            filedata = filedata.replace(key, value)\n",
    "    return filedata\n",
    "\n",
    "# Main function\n",
    "def input_data_ingestion(\n",
    "    project_id: str,\n",
    "    valid_test_rate: List[float],\n",
    "    location: str='us-central1',\n",
    "    secret_path: List[str]=None,\n",
    "    input_files_queries: List[str]=None,\n",
    "    input_files_storage_uri: List[str]=None,\n",
    "    test_mode: bool=False,\n",
    "    labels: List[str]=None,\n",
    "):\n",
    "    bf.options.bigquery.location = \"us\"  # Dataset is in 'us' not 'us-central1'\n",
    "    bf.options.bigquery.project = project_id\n",
    "\n",
    "    input_table_query = modify_query_file(input_files_queries[0], replacements={'@PROJECT_ID': project_id}, path='queries/')\n",
    "    \n",
    "    df = bf.read_gbq(query_or_table=input_table_query).to_pandas()\n",
    "\n",
    "    species_categories = {\n",
    "        \"versicolor\": 0,\n",
    "        \"virginica\": 1,\n",
    "        \"setosa\": 2,\n",
    "    }\n",
    "    df[\"species\"] = df[\"species\"].map(species_categories)\n",
    "\n",
    "    # Assign an index column name\n",
    "    index_col = \"index\"\n",
    "    df.index.name = index_col\n",
    "\n",
    "    feature_columns = df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
    "    label_columns = df[[\"species\"]]\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        feature_columns, label_columns, test_size=valid_test_rate[1]\n",
    "    )\n",
    "\n",
    "    print(\"X_train size: \", train_X.size)\n",
    "    print(\"X_test size: \", test_X.size)\n",
    "    \n",
    "    return (train_X, test_X, train_y, test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd8faa-5acb-448a-a98e-93d9bb203dbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Code to process input data and generate output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d24ef3-7875-4dc7-998e-c19625293655",
   "metadata": {
    "deletable": false,
    "editable": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# process (DON'T REMOVE THIS COMMENT)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "# Auxiliar functions\n",
    "# ...\n",
    "\n",
    "def feature_generation_from_input_data(\n",
    "    input_data: tuple,\n",
    "    project_id: str,\n",
    "    location: str='us-central1',\n",
    "    secret_path: List[str]=None,\n",
    "    test_mode: bool=False,\n",
    "    labels: List[str]=None\n",
    "):\n",
    "    train_X = input_data[0]\n",
    "    test_X = input_data[1]\n",
    "    train_y = input_data[2]\n",
    "    test_y = input_data[3]\n",
    "    \n",
    "    # Instantiate transformer\n",
    "    transformer = StandardScaler()\n",
    "\n",
    "    # Execute transformer on Vertex (train_X is bigframes.dataframe.DataFrame, X_train is np.array)\n",
    "    scaled_train_X = transformer.fit_transform(train_X)\n",
    "    train_X = pd.DataFrame(scaled_train_X, index=train_X.index, columns=train_X.columns)\n",
    "\n",
    "    # Execute transformer on Vertex (test_X is bigframes.dataframe.DataFrame, X_test is np.array)\n",
    "    scaled_test_X = transformer.transform(test_X)\n",
    "    train_X = pd.DataFrame(scaled_test_X, index=test_X.index, columns=test_X.columns)\n",
    "    \n",
    "    return (train_X, test_X, train_y, test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638d881-0876-460f-b634-84c5e0f7f7e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Code to save output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8daf3d2-bca7-4d48-a478-7ee14c45e473",
   "metadata": {
    "deletable": false,
    "editable": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output-data-storing (DON'T REMOVE THIS COMMENT)\n",
    "\n",
    "# Auxiliar functions\n",
    "# ...\n",
    "\n",
    "def feature_storing(\n",
    "    feature_data: tuple,\n",
    "    project_id: str,\n",
    "    labels: List[str]=None,\n",
    "    location: str='us-central1',\n",
    "    output_tables: List[str]=None,\n",
    "    output_bucket: List[str]=None,\n",
    "    secret_path: List[str]=None,\n",
    "    test_mode: bool=False\n",
    "):\n",
    "    train_X = feature_data[0]\n",
    "    test_X = feature_data[1]\n",
    "    train_y = feature_data[2]\n",
    "    test_y = feature_data[3]\n",
    "        \n",
    "    train_X = train_X.reset_index(drop=True)\n",
    "    train_y = train_y.reset_index(drop=True)\n",
    "\n",
    "    test_X = test_X.reset_index(drop=True)\n",
    "    test_y = test_y.reset_index(drop=True)\n",
    "\n",
    "    train_X.to_gbq(destination_table=output_tables[0], project_id=project_id, location=location, if_exists='replace')\n",
    "    test_X.to_gbq(destination_table=output_tables[1], project_id=project_id, location=location, if_exists='replace')\n",
    "    train_y.to_gbq(destination_table=output_tables[2], project_id=project_id, location=location, if_exists='replace')\n",
    "    test_y.to_gbq(destination_table=output_tables[3], project_id=project_id, location=location, if_exists='replace')\n",
    "    \n",
    "    return tuple([f'{project_id}.{table}' for table in output_tables])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7f641-f189-4e29-b11e-e8c1a2735f5b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Code to run every function in steps"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7537cbd-e3bb-4e9e-8b92-32eacf81fd4f",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": []
   },
   "source": [
    "# step-execution (DON'T REMOVE THIS COMMENT)\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    # Steps\n",
    "    input_data = input_data_ingestion(\n",
    "        project_id=project_id,\n",
    "        input_files_queries=input_files_queries,\n",
    "        valid_test_rate=valid_test_rate\n",
    "    )\n",
    "\n",
    "    feature_data = feature_generation_from_input_data(\n",
    "        project_id=project_id,\n",
    "        input_data=input_data\n",
    "    )\n",
    "\n",
    "    feature_location = feature_storing(\n",
    "        project_id=project_id,\n",
    "        feature_data=feature_data,\n",
    "        output_tables=output_tables\n",
    "    )\n",
    "\n",
    "    print(feature_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a025d737-cc89-42e2-9105-c5dd39ee766a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Standalone execution to test the functions\n",
    "Use a small dataset to have a sucess execution into this machine. Full dataset will be run in Vertex Training with enough resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12f93ad9-6bc8-4815-8dbe-820e8a42b7e3",
   "metadata": {
    "deletable": false,
    "editable": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Query job 7fb93f82-9423-4cb1-8ace-0053e8e4ff73 is DONE. 6.3 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=ml-framework-maas&j=bq:US:7fb93f82-9423-4cb1-8ace-0053e8e4ff73&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Query job 014578be-f524-4a9f-ae2c-c367e4d5b6f8 is DONE. 6.3 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=ml-framework-maas&j=bq:US:014578be-f524-4a9f-ae2c-c367e4d5b6f8&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  480\n",
      "X_test size:  120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 7449.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6432.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13231.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ml-framework-maas.model_test_iris.train_x', 'ml-framework-maas.model_test_iris.test_x', 'ml-framework-maas.model_test_iris.train_y', 'ml-framework-maas.model_test_iris.test_y')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# input variables\n",
    "project_id = 'ml-framework-maas'\n",
    "input_files_queries = ['input_data.sql']\n",
    "valid_test_rate = [0, 0.2]\n",
    "output_tables = [\"model_test_iris.train_x\", \"model_test_iris.test_x\", \"model_test_iris.train_y\", \"model_test_iris.test_y\"]\n",
    "\n",
    "# Steps\n",
    "input_data = input_data_ingestion(\n",
    "    project_id=project_id,\n",
    "    input_files_queries=input_files_queries,\n",
    "    valid_test_rate=valid_test_rate\n",
    ")\n",
    "    \n",
    "feature_data = feature_generation_from_input_data(\n",
    "    project_id=project_id,\n",
    "    input_data=input_data\n",
    ")\n",
    " \n",
    "feature_location = feature_storing(\n",
    "    project_id=project_id,\n",
    "    feature_data=feature_data,\n",
    "    output_tables=output_tables\n",
    ")\n",
    "\n",
    "print(feature_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71eda08-1ea6-4476-b20e-75f14f3306e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Create Vertex Training Job config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68cb9e-90f9-4a29-804f-95ba7afb9cb3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Create the requirements file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7016c4e-f85e-4451-8ee2-c0ddcd0f04e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pipdeptree in /opt/conda/envs/310-iris/lib/python3.10/site-packages (2.13.1)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x config/extract_dependencies.sh\n",
    "bash config/extract_dependencies.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a605f95-be87-4ab5-b49c-d25584476835",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Convert notebook to Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1c83e19-519b-46df-bef4-efa311aa9ef6",
   "metadata": {
    "deletable": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python config/convert_notebook2script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ceff37-1b6c-424b-a59c-8ef5dd2592c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Write function tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a7555-2012-4925-962e-2a87c22f0063",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Create a dataset for testing your functions in a manner that ensures a smooth transition to production, you should follow a structured approach.  \n",
    "This includes understanding the nature of your production data, replicating its structure in a testing environment, and ensuring that your test data adequately represents various scenarios and edge cases.\n",
    "\n",
    "* Define input values to run the functions with the test dataset.\n",
    "* Include the way to get the test dataset for functions. It must be small no more than 100 samples and very varied data.\n",
    "* Use this test dataset to run every created function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4968b4-dc9c-46ae-82a0-889ecc9d0f86",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "#### Define input values to run the functions with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b23fce3-1827-462c-9e6b-44de0f61dd3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# input variables\n",
    "project_id = 'ml-framework-maas'\n",
    "input_files_queries = ['test_input_data.sql']\n",
    "valid_test_rate = [0, 0.2]\n",
    "output_tables = [\"model_test_iris.test_mode_train_x\", \"model_test_iris.test_mode_test_x\", \"model_test_iris.test_mode_train_y\", \"model_test_iris.test_mode_test_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30fd9ae5-9304-42cb-937c-e423ed735ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def modify_query_file(input_name: str, replacements: dict={}, path='../scripts/queries/'):\n",
    "    \"\"\"\n",
    "    Modifies file in place with a dictionary of string replacements\n",
    "    \"\"\"\n",
    "    with open(path+input_name, 'r') as file :\n",
    "        filedata = file.read()\n",
    "    if replacements:\n",
    "        for key, value in replacements.items():\n",
    "            filedata = filedata.replace(key, value)\n",
    "    return filedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36457bec-02d0-46a1-9ced-9e574f9276f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "#### Way to get the test dataset for functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc71753d-98b7-4f20-ab99-78e3022b3594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query2create_test_dataset = modify_query_file('test_input_data_generation.sql', replacements={'@PROJECT_ID': project_id}, path='queries/')\n",
    "df_test_dataset = pd.read_gbq(query=query2create_test_dataset, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c918e36a-8f66-40ce-88d6-965ad37714a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0            4.5          2.3           1.3          0.3      setosa\n",
       "1            4.4          3.2           1.3          0.2      setosa\n",
       "2            4.8          3.0           1.4          0.1      setosa\n",
       "3            4.8          3.4           1.9          0.2      setosa\n",
       "4            4.8          3.4           1.6          0.2      setosa\n",
       "5            7.2          3.6           6.1          2.5   virginica\n",
       "6            7.4          2.8           6.1          1.9   virginica\n",
       "7            6.7          3.1           5.6          2.4   virginica\n",
       "8            4.9          2.5           4.5          1.7   virginica\n",
       "9            7.7          3.8           6.7          2.2   virginica\n",
       "10           5.5          2.4           3.8          1.1  versicolor\n",
       "11           5.7          2.9           4.2          1.3  versicolor\n",
       "12           5.6          2.9           3.6          1.3  versicolor\n",
       "13           6.4          2.9           4.3          1.3  versicolor\n",
       "14           6.5          2.8           4.6          1.5  versicolor"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750264f9-d702-4236-acca-b2f9cd354fb7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "#### Run functions with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "867ee8bb-edd8-4954-a859-15f87e70767c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Query job dd2848e7-e9f1-40ed-8bc4-89d41116946c is DONE. 635 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=ml-framework-maas&j=bq:US:dd2848e7-e9f1-40ed-8bc4-89d41116946c&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Query job 49ad38df-d16f-4391-af3d-509042a74579 is DONE. 635 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=ml-framework-maas&j=bq:US:49ad38df-d16f-4391-af3d-509042a74579&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  48\n",
      "X_test size:  12\n"
     ]
    }
   ],
   "source": [
    "input_data = input_data_ingestion(\n",
    "    project_id=project_id,\n",
    "    input_files_queries=input_files_queries,\n",
    "    valid_test_rate=valid_test_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c68af27b-988b-49dc-95fb-85a162b936b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "index                                                      \n",
       "14              7.2          3.6           6.1          2.5\n",
       "8               4.5          2.3           1.3          0.3\n",
       "4               4.9          2.5           4.5          1.7\n",
       "9               7.4          2.8           6.1          1.9\n",
       "5               6.5          2.8           4.6          1.5\n",
       "3               4.8          3.4           1.9          0.2\n",
       "13              6.7          3.1           5.6          2.4\n",
       "0               5.6          2.9           3.6          1.3\n",
       "10              7.7          3.8           6.7          2.2\n",
       "1               5.5          2.4           3.8          1.1\n",
       "11              4.8          3.0           1.4          0.1\n",
       "6               4.4          3.2           1.3          0.2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cbf55cf-d561-40e7-ab6b-0855f37d30ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_data = feature_generation_from_input_data(\n",
    "    project_id=project_id,\n",
    "    input_data=input_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40c39047-8307-420b-aa1f-403fb63d781c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.490646</td>\n",
       "      <td>-0.186469</td>\n",
       "      <td>0.201966</td>\n",
       "      <td>0.019335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.115446</td>\n",
       "      <td>-0.186469</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.019335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.894707</td>\n",
       "      <td>0.932343</td>\n",
       "      <td>-1.190311</td>\n",
       "      <td>-1.256757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "index                                                      \n",
       "2          0.490646    -0.186469      0.201966     0.019335\n",
       "7         -0.115446    -0.186469      0.150400     0.019335\n",
       "12        -0.894707     0.932343     -1.190311    -1.256757"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4957f158-6f26-4940-96da-64220d874d71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 9020.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9962.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7345.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9198.04it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_location = feature_storing(\n",
    "    project_id=project_id,\n",
    "    feature_data=feature_data,\n",
    "    output_tables=output_tables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4220c3b5-36e4-4ddb-b3fe-70b3f05d811e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ml-framework-maas.model_test_iris.test_mode_train_x',\n",
       " 'ml-framework-maas.model_test_iris.test_mode_test_x',\n",
       " 'ml-framework-maas.model_test_iris.test_mode_train_y',\n",
       " 'ml-framework-maas.model_test_iris.test_mode_test_y')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d8e4b-c3b5-43ad-b0e7-8392c4f5e528",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Define data quality rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf521e63-0b1f-47f6-bc80-68d94e52e8ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Encourage users to fill out these fields with as much accuracy and detail as possible.  \n",
    "Accurate metadata can significantly enhance data understanding, cleaning, processing, and analysis.  \n",
    "It will help in making informed decisions about data handling, modeling, and interpretation of results.  \n",
    "\n",
    "File that must be filled: **'tests/data_quality_metrics.xlsx'**\n",
    "\n",
    "Please fill out the following fields for each feature in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69071669-4cec-4ecf-be7d-5224ddc45c68",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "\n",
    "1. **column_name**: \n",
    "   - **Description:** The name of the column or field in your dataset.\n",
    "  \n",
    "2. **column_type**: \n",
    "   - **Description:** The data type of the column (e.g., integer, float, string, date).\n",
    "\n",
    "3. **min_value**: \n",
    "   - **Description**: The minimum value in the column. It's the smallest number in the case of numeric data.\n",
    "   - **Formula**: $\\text{min(Column)}$\n",
    "\n",
    "4. **mean_value**: \n",
    "   - **Description**: The average value of the column, calculated by summing all values and then dividing by the count of values.\n",
    "   - **Formula**: $\\text{Mean} = \\frac{\\sum_{i=1}^{n} X_i}{n}$\n",
    "\n",
    "5. **max_value**: \n",
    "   - **Description**: The maximum value in the column. It's the largest number in the case of numeric data.\n",
    "   - **Formula**: $\\text{max(Column)}$\n",
    "\n",
    "6. **outliers_count**: \n",
    "   - **Description**: The count of values significantly different from others. Outliers are often determined using statistical methods like the Z-score, where $\\text{k}$ is a threshold value (commonly 1.96 for 95% confidence).\n",
    "   - **Formula**: Count values where $|X_i - \\text{Mean}| > k \\times \\text{Standard Deviation}$\n",
    "\n",
    "7. **nulls_count**: \n",
    "   - **Description**: The number of missing or undefined values in the column.\n",
    "   - **Formula**: Count of `Null` or `NaN` values in the Column.\n",
    "\n",
    "8. **rows_count**: \n",
    "   - **Description**: Simply the count of all rows or records in the dataset.\n",
    "   - **Formula**: Total number of rows in the dataset.\n",
    "\n",
    "9. **cardinality**: \n",
    "   - **Description**: The number of distinct values in the column.\n",
    "   - **Formula**: Count of unique values in the Column.\n",
    "\n",
    "10. **selectivity**: \n",
    "    - **Description**: The ratio of unique values to total rows, indicating how many rows can be filtered using a particular value.\n",
    "    - **Formula**: $\\text{Selectivity} = \\frac{\\text{Number of Unique Values}}{\\text{Total Number of Rows}}$\n",
    "\n",
    "11. **density**: \n",
    "    - **Description**: The proportion of non-null values to total values in the column, indicating how \"filled\" a column is with non-null data.\n",
    "    - **Formula**: Typically calculated as $\\text{Density} = \\frac{\\text{Non-Null Count}}{\\text{Total Count}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a19f52f7-1a44-4eaa-9cf7-0445d3b5bdd7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>min_value</th>\n",
       "      <th>mean_value</th>\n",
       "      <th>max_value</th>\n",
       "      <th>outliers_count</th>\n",
       "      <th>nulls_count</th>\n",
       "      <th>rows_count</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>selectivity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('tests/data_quality_metrics.xlsx')\n",
    "html_table = df.to_html()\n",
    "\n",
    "display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cb774-c59a-4ccd-9121-4dfbcff2e721",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Create docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1f16c23-2320-42e7-9208-c6a3c0de9b8b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  402.4kB\n",
      "Step 1/9 : ARG PYTHON_VERSION=3.9\n",
      "Step 2/9 : FROM python:${PYTHON_VERSION}-slim-buster\n",
      " ---> 93b9055430ce\n",
      "Step 3/9 : ARG PROJECT_DIRECTORY=\"/usr/app\"\n",
      " ---> Using cache\n",
      " ---> 64ecca38c846\n",
      "Step 4/9 : WORKDIR ${PROJECT_DIRECTORY}\n",
      " ---> Using cache\n",
      " ---> d2946e60194d\n",
      "Step 5/9 : RUN apt update && apt-get install g++ -yy\n",
      " ---> Using cache\n",
      " ---> 5ab8176babc3\n",
      "Step 6/9 : COPY requirements.txt requirements.txt\n",
      " ---> Using cache\n",
      " ---> b87a06f16002\n",
      "Step 7/9 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 581e3d3693f9\n",
      "Step 8/9 : COPY . .\n",
      " ---> 0b9146342259\n",
      "Step 9/9 : ENTRYPOINT [\"python3\", \"src/main.py\"]\n",
      " ---> Running in b8073fe01531\n",
      "Removing intermediate container b8073fe01531\n",
      " ---> 368b29568773\n",
      "Successfully built 368b29568773\n",
      "Successfully tagged us-central1-docker.pkg.dev/ml-framework-maas/datascience-test3/mvp/iris_classification/preprocessing:latest\n",
      "Deleted Images:\n",
      "untagged: us-central1-docker.pkg.dev/ml-framework-maas/datascience-test3/mvp/iris_classification/preprocessing@sha256:3802c3a48601b4c2f2cbffadad251b14e896151d53692cf843742ab1915e5684\n",
      "deleted: sha256:9e6218a33c82f96529172b6721e4a1cc0abb7684667b4bccc111457fc4985266\n",
      "deleted: sha256:9ed6b4db7206354837ba2fe32d0f91b77ab1d3f24af4004e93b5ce9a87282e57\n",
      "deleted: sha256:6779ac8f14ec0add3d9299866b8a250f573e5c0623bb54c7af1ae25b806ef1f2\n",
      "\n",
      "Total reclaimed space: 285.8kB\n",
      "The push refers to repository [us-central1-docker.pkg.dev/ml-framework-maas/datascience-test3/mvp/iris_classification/preprocessing]\n",
      "592229a779c4: Preparing\n",
      "d9b673500ba7: Preparing\n",
      "67247d41e7fd: Preparing\n",
      "a72e9009de1d: Preparing\n",
      "a17964926ad2: Preparing\n",
      "c5321f7f53ff: Preparing\n",
      "df6c1b185b95: Preparing\n",
      "b23fedba7dbd: Preparing\n",
      "ae2d55769c5e: Preparing\n",
      "e2ef8a51359d: Preparing\n",
      "b23fedba7dbd: Waiting\n",
      "c5321f7f53ff: Waiting\n",
      "df6c1b185b95: Waiting\n",
      "ae2d55769c5e: Waiting\n",
      "e2ef8a51359d: Waiting\n",
      "67247d41e7fd: Layer already exists\n",
      "d9b673500ba7: Layer already exists\n",
      "a72e9009de1d: Layer already exists\n",
      "a17964926ad2: Layer already exists\n",
      "df6c1b185b95: Layer already exists\n",
      "c5321f7f53ff: Layer already exists\n",
      "ae2d55769c5e: Layer already exists\n",
      "b23fedba7dbd: Layer already exists\n",
      "e2ef8a51359d: Layer already exists\n",
      "592229a779c4: Pushed\n",
      "latest: digest: sha256:5ed89bdd68f3a9029a18615f9c20739138f9cc466169d2b6650fc38e5207ec7c size: 2418\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x config/build-img.sh\n",
    "bash config/build-img.sh -m iris_classification -p 3.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bba99-57ff-4bb0-a1b6-59208b6f88b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Launch Vertex Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd1ff196-45e4-496d-afc0-b8441bddf615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cpu_machine_name': 'n1-standard-8', 'cpu_machine_cores': 8, 'cpu_machine_ram': 30}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python config/find_suitable_gcp_machine.py --cpu_cores=5 --ram_gb=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6440db7-b0c5-47a2-8018-a344dc3133c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/1099093996594/locations/us-central1/customJobs/1465807123341377536] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/1099093996594/locations/us-central1/customJobs/1465807123341377536\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/1099093996594/locations/us-central1/customJobs/1465807123341377536\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x config/launch_custom_job.sh\n",
    "bash config/launch_custom_job.sh \\\n",
    "-m 'iris_classification' \\\n",
    "-c 'n1-standard-4' \\\n",
    "-i 'us-central1-docker.pkg.dev/ml-framework-maas/datascience-test3/mvp/iris_classification/preprocessing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6367eb8-6b42-4a36-9f09-d71728bcc643",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729fd121-eb9a-4577-8597-a6fbb42737ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Experimental code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440e2de-bb89-4d0b-8b6e-a595ada1026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigframes.pandas as bf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159c880-5d21-4eea-9b7e-34fb0e5bb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf.options.bigquery.location = \"us\"  # Dataset is in 'us' not 'us-central1'\n",
    "bf.options.bigquery.project = 'ml-framework-maas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981fb107-1c20-4a25-a395-20d08d8a2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bf.read_gbq(\"bigquery-public-data.ml_datasets.iris\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b16f6fe-16e6-4905-9966-66f64cfe748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_categories = {\n",
    "    \"versicolor\": 0,\n",
    "    \"virginica\": 1,\n",
    "    \"setosa\": 2,\n",
    "}\n",
    "df[\"species\"] = df[\"species\"].map(species_categories)\n",
    "\n",
    "# Assign an index column name\n",
    "index_col = \"index\"\n",
    "df.index.name = index_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00746c-a8c9-46f8-808f-fa8f337c53aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
    "label_columns = df[[\"species\"]]\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    feature_columns, label_columns, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce93330-92df-46b5-8b58-fa1d1a3ef4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train size: \", train_X.size)\n",
    "print(\"X_test size: \", test_X.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e65bab-ff5a-44aa-995a-fdf6a6572d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate transformer\n",
    "transformer = StandardScaler()\n",
    "\n",
    "# Execute transformer on Vertex (train_X is bigframes.dataframe.DataFrame, X_train is np.array)\n",
    "X_train = transformer.fit_transform(train_X)\n",
    "     \n",
    "# Execute transformer on Vertex (test_X is bigframes.dataframe.DataFrame, X_test is np.array)\n",
    "X_test = transformer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d8ecd-ae20-4eea-b52d-07a5ff2bfcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate model, warm_start=True for uptraining\n",
    "model = LogisticRegression(warm_start=True)\n",
    "\n",
    "# Train model on Vertex\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3a032-34d5-4488-b8d8-9691178eb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_X)\n",
    "\n",
    "print(f\"Remote predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0857df-9cb9-4ca5-b9be-f07587ddfec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User must convert bigframes to pandas dataframe for local evaluation\n",
    "train_X_pd = train_X.reset_index(drop=True)\n",
    "train_y_pd = train_y.reset_index(drop=True)\n",
    "\n",
    "test_X_pd = test_X.reset_index(drop=True)\n",
    "test_y_pd = test_y.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9528770-b2d6-4aed-8d8b-5b2a7d7319df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model's accuracy score\n",
    "print(f\"Train accuracy: {model.score(train_X_pd, train_y_pd)}\")\n",
    "\n",
    "print(f\"Test accuracy: {model.score(test_X_pd, test_y_pd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5704a-ac80-4175-8bfb-641b3ee6f673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-310-iris-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python (310-iris) (Local)",
   "language": "python",
   "name": "conda-env-310-iris-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
